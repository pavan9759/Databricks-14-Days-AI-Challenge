{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ff6c5bf-6562-4119-8a44-34f66a8ce99b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE VOLUME IF NOT EXISTS workspace.ecommerce.bronze;\n",
    "CREATE VOLUME IF NOT EXISTS workspace.ecommerce.silver;\n",
    "CREATE VOLUME IF NOT EXISTS workspace.ecommerce.gold;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0858731e-4dc9-4ddb-94f7-75b185f7bf46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "SHOW VOLUMES IN workspace.ecommerce;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc072f1a-a8fa-4dcc-a827-a370ba9819b9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Bronze"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, to_timestamp\n",
    "\n",
    "# Step 1: Read raw CSV files (Bronze ingestion)\n",
    "df = spark.read.csv(\n",
    "    [\n",
    "        \"/Volumes/workspace/ecommerce/ecommerce_data/2019-Oct.csv\",\n",
    "        \"/Volumes/workspace/ecommerce/ecommerce_data/2019-Nov.csv\"\n",
    "    ],\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "# Step 2: Cast event_time column to timestamp\n",
    "raw = df.withColumn(\n",
    "    \"event_time\",   #DataFrame me event_time column ko update (change) karna.\n",
    "    to_timestamp(col(\"event_time\"))   #event_time ko TEXT se DATE-TIME banana\n",
    ")\n",
    "\n",
    "# Step 3: Add ingestion timestamp for audit and tracking\n",
    "bronze = raw.withColumn(\n",
    "    \"ingestion_ts\",  # DataFrame me ek naya column ingestion_ts add (create) karna.\n",
    "     F.current_timestamp() \n",
    ")\n",
    "\n",
    "# Step 4: Write data to Bronze layer in Delta format (append only)\n",
    "bronze.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save(\"/Volumes/workspace/ecommerce/ecommerce_data/bronze\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a291d67-31b0-464d-807b-411bd96e845b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Silver "
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Read Bronze layer\n",
    "bronze = (\n",
    "    spark.read\n",
    "    .format(\"delta\")\n",
    "    .load(\"/Volumes/workspace/ecommerce/ecommerce_data/bronze\")\n",
    ")\n",
    "\n",
    "# Silver transformations\n",
    "silver = (\n",
    "    bronze\n",
    "    .filter(F.col(\"price\").isNotNull())\n",
    "    .filter((F.col(\"price\") > 0) & (F.col(\"price\") < 10000))\n",
    "    .dropDuplicates([\"user_id\", \"product_id\", \"event_time\"])\n",
    "    .withColumn(\"event_date\", F.to_date(\"event_time\"))\n",
    "    .withColumn(\n",
    "        \"price_tier\",\n",
    "        F.when(F.col(\"price\") < 10, \"budget\")\n",
    "         .when(F.col(\"price\") < 50, \"mid\")\n",
    "         .otherwise(\"premium\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Write Silver layer\n",
    "(\n",
    "    silver.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"event_date\")\n",
    "    .save(\"/Volumes/workspace/ecommerce/ecommerce_data/silver\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28476e4e-50e2-4d18-93d4-418c5fefec6c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Gold"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Read Silver layer\n",
    "silver = spark.read.format(\"delta\") \\\n",
    "    .load(\"/Volumes/workspace/ecommerce/ecommerce_data/silver\")\n",
    "\n",
    "# Gold aggregations (business metrics)\n",
    "product_perf = (\n",
    "    silver.groupBy(\"brand\")\n",
    "    .agg(\n",
    "        F.countDistinct(\n",
    "            F.when(F.col(\"event_type\") == \"view\", F.col(\"user_id\"))\n",
    "        ).alias(\"views\"),\n",
    "\n",
    "        F.countDistinct(\n",
    "            F.when(F.col(\"event_type\") == \"purchase\", F.col(\"user_id\"))\n",
    "        ).alias(\"purchases\"),\n",
    "\n",
    "        F.sum(\n",
    "            F.when(F.col(\"event_type\") == \"purchase\", F.col(\"price\"))\n",
    "        ).alias(\"revenue\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"conversion_rate\",\n",
    "        F.when(\n",
    "            F.col(\"views\") > 0,\n",
    "            (F.col(\"purchases\") / F.col(\"views\")) * 100\n",
    "        ).otherwise(0)\n",
    "    )\n",
    "    .orderBy(\"brand\")\n",
    ")\n",
    "\n",
    "# Write Gold layer\n",
    "product_perf.write.format(\"delta\") \\ \n",
    "    .mode(\"overwrite\") \\ \n",
    "    .save(\"/Volumes/workspace/ecommerce/ecommerce_data/gold\") \n",
    "gold = spark.read.format(\"delta\").load(\"/Volumes/workspace/ecommerce/ecommerce_data/gold\")\n",
    "display(gold) "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7811842920049487,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 6",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
